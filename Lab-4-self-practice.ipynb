{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer, load_digits\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 82,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "   survived  pclass     sex    age  sibsp  parch      fare embarked\n0         1       1  female  29.00      0      0  211.3375        S\n1         1       1    male   0.92      1      2  151.5500        S\n2         0       1  female   2.00      1      2  151.5500        S\n3         0       1    male  30.00      1      2  151.5500        S\n4         0       1  female  25.00      1      2  151.5500        S",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>survived</th>\n      <th>pclass</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>fare</th>\n      <th>embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>29.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211.3375</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>0.92</td>\n      <td>1</td>\n      <td>2</td>\n      <td>151.5500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>female</td>\n      <td>2.00</td>\n      <td>1</td>\n      <td>2</td>\n      <td>151.5500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>male</td>\n      <td>30.00</td>\n      <td>1</td>\n      <td>2</td>\n      <td>151.5500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>female</td>\n      <td>25.00</td>\n      <td>1</td>\n      <td>2</td>\n      <td>151.5500</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('titanic.csv')\n",
    "# removing name column\n",
    "data = data.drop(['name'], axis = 1)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.loc[:, 'pclass':], data['survived'],\n",
    "                                                    test_size=0.2, stratify=data['survived'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preprocessing\n",
    "NB can handle discrete features data which can be useful with categorical data.\n",
    "\n",
    "Let's see one of the advantages of NB classifier. NB is not affected by data scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# imputing missing values\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputer.fit(x_train)\n",
    "x_train = pd.DataFrame(imputer.transform(x_train), columns=x_train.columns)\n",
    "x_test = pd.DataFrame(imputer.transform(x_test), columns=x_test.columns)\n",
    "\n",
    "# one-hot-encode categorical features\n",
    "def ohe_new_features(df, features_name, encoder):\n",
    "    new_feats = encoder.transform(df[features_name])\n",
    "    # create dataframe from encoded features with named columns\n",
    "    new_cols = pd.DataFrame(new_feats, dtype=int, columns=encoder.get_feature_names(features_name))\n",
    "    new_df = pd.concat([df, new_cols], axis=1)\n",
    "    new_df.drop(features_name, axis=1, inplace=True)\n",
    "    return new_df\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "f_names = ['sex', 'embarked']\n",
    "encoder.fit(x_train[f_names])\n",
    "x_train = ohe_new_features(x_train, f_names, encoder)\n",
    "x_test = ohe_new_features(x_test, f_names, encoder)\n",
    "\n",
    "# feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "scaled_x_train = pd.DataFrame(scaler.transform(x_train), columns=x_train.columns)\n",
    "scaled_x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train and test two NB models ono the data before scaling and one after scaling\n",
    "and observe if the accuracy change with scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before scaling: 0.7824427480916031\n",
      "Accuracy after scaling: 0.648854961832061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "# Write code here\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred = nb.predict(x_test)\n",
    "print('Accuracy before scaling:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Write code here\n",
    "nb = MultinomialNB()\n",
    "nb.fit(scaled_x_train, y_train)\n",
    "y_pred = nb.predict(scaled_x_test)\n",
    "print('Accuracy after scaling:', accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regularization\n",
    "What is [Elastic-Net](https://scikit-learn.org/stable/modules/linear_model.html#elastic-net)?\n",
    "How can you specify the contribution of each part using l1 ration\n",
    "\n",
    "Apply classification on the breast cancer dataset with no regularization, l1,\n",
    "l2, and elastic-net."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading Breast cancer dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 87,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fitting both Lasso and Ridge\n",
    "\n",
    "Fit 3 models: Lasso and Ridge and Elastic-Net.\n",
    "Then print their accuracy and coefficients and notice the difference."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Score: 0.5050858502268123,\n",
      " Coefs: [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.38172126e-04\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -5.56784681e-05 -4.84280802e-04\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00]\n",
      "Ridge Score 0.7409047788188938,\n",
      " Coefs: [ 0.17447188  0.00153045 -0.00513055 -0.00128325 -0.11818432 -0.01683136\n",
      " -0.13128865 -0.22476034 -0.15232779 -0.00792515 -0.12750205  0.02721072\n",
      " -0.04046861  0.00138772 -0.0483056   0.0575303   0.15943928 -0.03971724\n",
      " -0.02204321  0.0055686  -0.26742486 -0.01464427  0.00942734  0.00125219\n",
      " -0.27686671 -0.11419131 -0.21257358 -0.45126176 -0.31185673 -0.06081197]\n",
      "ElasticNet Score 0.599191262864027,\n",
      " Coefs: [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -8.60114343e-04 -1.06421822e-02 -1.10486455e-05\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso, ElasticNet\n",
    "\n",
    "# Write code here\n",
    "lasso = Lasso()\n",
    "ridge = Ridge()\n",
    "elasticnet = ElasticNet()\n",
    "lasso.fit(x_train, y_train)\n",
    "ridge.fit(x_train, y_train)\n",
    "elasticnet.fit(x_train, y_train)\n",
    "print(f'Lasso Score: {lasso.score(x_test, y_test)},\\n Coefs: {lasso.coef_}')\n",
    "print(f'Ridge Score {ridge.score(x_test, y_test)},\\n Coefs: {ridge.coef_}')\n",
    "print(f'ElasticNet Score {elasticnet.score(x_test, y_test)},\\n Coefs: {elasticnet.coef_}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KNN\n",
    "Compare KNN vs logistic regression\n",
    "\n",
    "---\n",
    "In ML images can be flattened to 1D vector of pixels, then we can train our\n",
    "models on them considering each pixel as a feature."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape (1797, 8, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGzCAYAAAASUAGgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmK0lEQVR4nO3de3BU9f3G8Sf3C1khIAUJKgFhEWK42SKYHzRIO0pFCQiiRlKGOlCxVoEWtZ2BIBi0rVYhKspFJEIarhq8VauoFaYwVi5SytBCAKNCJqBu7pLs749MUlYUcsL5sGx4v2acuIfd5/shOXuenLMhG+b3+/0CAMBl4cEeAADQMlEwAAATFAwAwAQFAwAwQcEAAExQMAAAExQMAMAEBQMAMEHBAABMUDAAABORwR4AOFter7dJ93vxxRc1cOBA42ma7p///Kc+/PBDZWVl6aKLLjrrrD/84Q/617/+pYSEBN1www26//771apVK5emBZyjYBDyHnvssYDbL7/8sj788MNTtnfr1u1cjnVGH3/8sRYuXKiMjIyzKpg9e/bo5z//ubp166YHHnhAX3zxhZYuXaqioiItXrzYxYkBZygYhLybb7454PaOHTv04YcfnrK9Ofx+v6qrqxUbG3vWWVYef/xxXXTRRVqxYoUSEhIkSZ07d9bvf/97/f3vf1daWlqQJ8SFitdgcEFYu3atJkyYoEGDBiklJUUjRozQypUrT7nfsGHDNHnyZH3wwQcaPXq0UlNTlZ+fL0kqLi7WlClT1LdvXw0aNEiPPPKIPvjgA3m9Xv3jH/8IyNmxY4cmTZqkAQMGqE+fPsrMzNRHH33U+OcLFixoPMO67rrr5PV65fV69emnn0qSjh07pv/+97+qrKw87d+rrKxMmzdv1k033dRYLlJ96cbHx+v1119v3icMcAFnMLggrFq1St27d9ewYcMUGRmpd999V9nZ2fL7/brjjjsC7nvgwAFNnz5dt956q8aNG6fk5GRVVFQoKytLJSUlmjBhgi6++GJt3LjxlGKRpC1btuiuu+5SSkqK7rnnHoWFhWndunXKysrSypUrlZqaqp/85CcqKirSxo0b9eCDDyoxMVGS1LZtW0nSSy+9pIULF57xdaO9e/fqxIkTSklJCdgeHR2tK6+8Unv27DnbTx3QbBQMLgh5eXkBl7kyMzM1adIkLVu27JSCOXjwoBYvXqz/+7//a9y2bNkyHT58WLm5uRo+fLgkafz48Ro1alTAY/1+v2bPnq2BAwdq8eLFCgsLa7zvz372M/35z3/W0qVL1bNnT/Xq1UsbN27U8OHD1blz52b9vUpKSiRJP/jBD075s/bt2wecNQHnGpfIcEE4uVx8Pp+OHTumH/3oRzp8+LB8Pl/AfTt37hxQLpL0wQcfqEOHDrruuusat8XExGjcuHEB99uzZ4+Kioo0cuRIHT9+XMeOHdOxY8dUUVGhQYMGadu2baqrqzvjvL/61a+0d+/eM/7UW1VVlaT6M5Zvi4mJafxzIBg4g8EF4aOPPtKCBQu0ffv2U17X8Pl88ng8jbe/62yiuLhYl112WeMZSYPLLrss4HZRUZEkaebMmd87i8/nU+vWrZ3+Fb5TQ3HW1NSc8mfn+w8noOWjYNDiHTp0SD//+c/VtWtXPfDAA7rkkksUFRWl9957Ty+88MIpZxRnc1BueAfy3/72t7ryyiu/8z7x8fHNzv+29u3bS5KOHj16yp+VlJR856Uz4FyhYNDivfPOO6qpqdEzzzyjTp06NW7/rhfov09SUpL+85//yO/3B5zFHDp0KOB+l156qSQpISFBgwcPPm3mt8+GmqNHjx6KjIzUJ598ohEjRjRur6mp0Z49e3TDDTec9RpAc/EaDFq8iIgISf87u5DqL1OtXbu2yRlpaWk6cuSI/va3vzVuq66uVkFBQcD9UlJSdNlll2np0qUqLy8/JefYsWON/x8XF9c4y3fdryk/puzxeDRo0CC98sorKisra9z+8ssvq6KiQtdff33T/oKAAc5g0OJde+21ioqK0pQpUzR+/HiVl5dr9erVateuXeNPYZ3Jrbfeqry8PE2fPl0TJkxQ+/btVVhYqJiYGEn/OxsJDw/X3Llzddddd+nGG2/U6NGj1aFDBx05ckT/+Mc/lJCQoGeffVaS1Lt3b0nSE088oREjRigqKkrp6emKj49v8o8pS9L999+v8ePH684779S4ceP0xRdfaNmyZUpLS9OQIUOa+2kDzhpnMGjxunbtqqeeekphYWF69NFHlZ+fr3HjxmnChAlNzmjVqpWWL1+ua665Ri+++KKeeeYZXX311br77rslqbFoJGngwIH6y1/+opSUFOXl5enhhx/W+vXrdfHFFysrK6vxfqmpqfr1r3+tf//733rwwQc1bdq0gDOcpurdu7eWLVummJgY5eTkqKCgQLfccouefPJJx1mAm8L8J183AODICy+8oJycHL3//vvq0KFDsMcBziucwQBN9O1/U1JdXa2//OUv6tKlC+UCfAdegwGa6J577lGnTp3Us2dPlZWV6ZVXXtH+/fv1xz/+MdijAeclLpEBTfTCCy9ozZo1Ki4uVm1tra644gr94he/CPjxYAD/Q8EAAEzwGgwAwAQFAwAwQcEAAExQMAAAE0H7MeWkpKTv/B1MZ8Pj8ai4uNgk25L13BkZGa5nSvW/dXjRokWaPHmy2fuOzJ492/XMsLAwdenSRUVFRbL6GZdNmza5nhkVFaXMzEzl5eXpm2++cT1fsvl8S/W//HP37t3q3bt3wO9Mc8vx48ddz5Q4ppwuuymCVjA+n8/sC2aZbclq7jP9wsSzVVVVZbaG5Q85+v1+s3yrAmjItsq3ft6UlZWZrGE9N8eU5uESGQDABAUDADBBwQAATFAwAAATFAwAwAQFAwAwQcEAAExQMAAAExQMAMAEBQMAMEHBAABMUDAAABMUDADABAUDADBBwQAATFAwAAATzSqYl156ScOGDdNVV12lsWPHaufOnW7PBQAIcY4L5rXXXlNOTo6mTp2q9evXq2fPnpo0aZJKS0st5gMAhCjHBbNs2TKNGzdOY8aM0RVXXKHs7GzFxsZq7dq1FvMBAEJUpJM719TUaPfu3Zo8eXLjtvDwcA0ePFgff/yxo4U9Ho+j+zvJtMi2ZD13XFycSW5sbGzARwthYWFmmRbZDaKioswyLbIbWO2DCQkJAR/dduLECZNcjinfn90UYX6/39/UOx85ckRDhgxRfn6++vXr17j9scce07Zt27R69WpnkwIAWixHZzBuSkpKks/nczXT4/GouLjYJNuS9dwZGRmuZ0r1Zy6LFi3S5MmTVVVVZbLG7NmzXc8MCwtTly5dVFRUJAffXzmyadMm1zOjoqKUmZmpvLw8ffPNN67nSzafb6n+zGX37t3q3bu3ysrKXM8/fvy465kSx5TTZTeFo4JJTExURETEKS/ol5aW6uKLL3YSJZ/PZ/YFs8y2ZDV3ZWWl65knq6qqMlvDqgAasq3yrQqgIdsq3/p5U1ZWZrKG9dwcU5rH0Yv80dHR6t27t7Zs2dK4ra6uTlu2bAm4ZAYAgONLZBMnTtTMmTOVkpKi1NRULV++XJWVlRo9erTFfACAEOW4YEaMGKFjx47pqaeeUklJia688kotXrzY8SUyAEDL1qwX+TMzM5WZmen2LACAFoTfRQYAMEHBAABMUDAAABMUDADABAUDADBBwQAATFAwAAATFAwAwAQFAwAwQcEAAExQMAAAExQMAMAEBQMAMEHBAABMUDAAABPNej8YhJb58+eb5IaFhUmSZs+ebfbe9l27djXJlaTk5GSz7MTERNczIyPrn65t2rTRiRMnXM+XpGPHjpnkNjh48KBJ7rhx40xy4+LiJEkZGRmqrKw0WWP16tUmuecDzmAAACYoGACACQoGAGCCggEAmKBgAAAmKBgAgAkKBgBggoIBAJigYAAAJigYAIAJCgYAYIKCAQCYoGAAACYoGACACQoGAGCCggEAmKBgAAAmKBgAgAkKBgBgwnHBbNu2TVOmTFFaWpq8Xq/efvtti7kAACHOccFUVFTI6/Vq1qxZFvMAAFqISKcPGDp0qIYOHWoxCwCgBXFcMG7xeDxmmRbZlqznDgsLM821yg9lkZHuP7UaMi2yQ11cXJxJbmxsbMBHC6F2LHSSGeb3+/3NXcjr9So3N1fDhw9vbgQAoIUK2rdCSUlJ8vl8rmZ6PB4VFxebZFuynnvHjh2uZ0r1Zy5dunRRUVGRzuL7lNNKTk42ybW2fv161zMjIyM1cuRIFRYW6sSJE67nS1JGRoZJrrWsrCyT3NjYWC1atEiTJ09WVVWVyRoW+4rlMaUhuymCVjA+n8+sBCyzLVnNbXXwPznfeo1QY1UADdmW+aGosrLSNL+qqspsDctjVbCPhfw7GACACcdnMOXl5Tp06FDj7U8//VR79uxR69at1alTJ1eHAwCELscF88knn2jChAmNt3NyciTVX7udP3++e5MBAEKa44IZOHCg9u7dazELAKAF4TUYAIAJCgYAYIKCAQCYoGAAACYoGACACQoGAGCCggEAmKBgAAAmKBgAgAkKBgBggoIBAJigYAAAJigYAIAJCgYAYIKCAQCYcPx+MBeyAQMGmOS2atVKktSvXz+Vl5e7nt+1a1fXM0+WnJxslt2tWzfXMxMSErRjxw716dNHZWVlrudL0v79+13P9Hg8ysjIUFZWltn7rL/11lsmuREREUpPT9e7776r2tpa1/OtnpvR0dGSpL59+6qmpsZkjdWrV5vkng84gwEAmKBgAAAmKBgAgAkKBgBggoIBAJigYAAAJigYAIAJCgYAYIKCAQCYoGAAACYoGACACQoGAGCCggEAmKBgAAAmKBgAgAkKBgBggoIBAJigYAAAJigYAICJSCd3XrRokf76179q//79io2NVb9+/TRjxgzz93wHAIQeR2cwW7du1R133KGCggItW7ZMJ06c0KRJk1RRUWE1HwAgRDk6g1myZEnA7fnz52vQoEHavXu3fvjDH7o6GAAgtDkqmG/z+XySpNatWzt+rMfjOZulT5tpkS1JrVq1MsmNj48P+Ij/SUhIcD2z4eto9fWUQnP/lqSIiAjTXKv86Oho01yrfCn09hUnmWF+v9/fnEXq6ur0y1/+Ul9//bVWrVrVnAgAQAvW7DOY7Oxs7du3TytXrmzW45OSkhrPgNzi8XhUXFxski1J/fr1cz1Tqj9zef3113XDDTeYvJ713nvvuZ55rvTp08f1zFatWmnz5s0aPHiwysvLXc+XpAMHDrieab1/S9LLL79skhsREaEhQ4bo/fffV21trev527dvdz1Tqj9zmTp1qnJzc1VTU2OyxqxZs1zPtNxXGrKbolkFM2fOHG3atEl5eXnq2LFjcyLk8/nMniRW2VYHowYVFRXma4SasrIys+zy8nKzfKt9uyHbKt/i4P/tfIs1rA7+J+dbrRGq+0pTOCoYv9+vhx9+WG+99ZZWrFihSy+91GouAECIc1Qw2dnZ2rhxo55++mm1atVKJSUlkupPmWJjY00GBACEJkcF0/Bi/p133hmwPScnR6NHj3ZvKgBAyHNUMHv37rWaAwDQwvC7yAAAJigYAIAJCgYAYIKCAQCYoGAAACYoGACACQoGAGCCggEAmKBgAAAmKBgAgAkKBgBggoIBAJigYAAAJigYAIAJCgYAYIKCAQCYcPSGYxe6xMREk9z4+HhJUps2bRQdHe16/kcffeR6piSFh4erX79++vjjj1VXV2eyxv79+13P9Hg8kqQDBw7I5/O5nh/KrPaV6Ohopaena/v27aqpqTFZA+cfzmAAACYoGACACQoGAGCCggEAmKBgAAAmKBgAgAkKBgBggoIBAJigYAAAJigYAIAJCgYAYIKCAQCYoGAAACYoGACACQoGAGCCggEAmKBgAAAmKBgAgAkKBgBgItLJnVeuXKlVq1apuLhYktS9e3fdfffdGjp0qMlwAIDQ5ahgOnbsqBkzZujyyy+X3+/Xhg0bNHXqVK1fv17du3e3mhEAEIIcFcywYcMCbt9///1atWqVtm/f7rhgPB6Po/s7ybTIlqT4+HiT3Li4uICPbgsPt7kS2pBrlS+F5n5i5VzMHR0dbZprlW/lXMwdavu4k8wwv9/vb84itbW1euONNzRz5kxt2LBBV1xxRXNiAAAtlKMzGEnau3evxo8fr+rqasXHxys3N7dZ5ZKUlCSfz+f4cafj8XhUXFxski1J6enprmdK9Wcu+fn5Gj9+vCorK13Pnz17tuuZUv2ZS58+fbRjxw7V1dWZrGHx+p71fmLlXMydnZ1tkhsdHa2pU6cqNzdXNTU1JmtYOBdzz5o1y/VMy32lIbspHBdMcnKyNmzYIJ/PpzfffFMzZ85UXl6e45Lx+XxmTxKr7IqKCtczT1ZZWWmyhtXB/+R8qzUsC8ByH7RkObf1wb+mpiakCqaB5dwteR93fPE8Ojpal19+uVJSUjR9+nT17NlTL774osVsAIAQdtavztbV1YXkdyQAAFuOLpH96U9/0pAhQ3TJJZeovLxcGzdu1NatW7VkyRKr+QAAIcpRwZSWlmrmzJk6evSoPB6PvF6vlixZomuvvdZqPgBAiHJUMI888ojVHACAFobfRQYAMEHBAABMUDAAABMUDADABAUDADBBwQAATFAwAAATFAwAwAQFAwAwQcEAAExQMAAAExQMAMAEBQMAMEHBAABMUDAAABOO3g/mQpeYmGiSGxcXJ0lq06aNYmJiXM9/++23Xc+UpOjoaPXr10+bNm3ibbNbCKt9PCoqSlL9Pv7NN9+4nn/8+HHXM3H2OIMBAJigYAAAJigYAIAJCgYAYIKCAQCYoGAAACYoGACACQoGAGCCggEAmKBgAAAmKBgAgAkKBgBggoIBAJigYAAAJigYAIAJCgYAYIKCAQCYoGAAACYoGACAibMqmOeee05er1fz5s1zax4AQAvR7ILZuXOn8vPz5fV63ZwHANBCNKtgysvL9Zvf/EZz585V69at3Z4JANACRDbnQXPmzNHQoUM1ePBgPfPMM81a2OPxNOtxTcm0yJakuLg4k9zY2NiAj26Ljo42zbXKl0JzP7FyLuaOiooyzbXKZx//7kzL7KYI8/v9fifhr776qp599lmtWbNGMTExuvPOO9WzZ0/97ne/czwoAKDlcnQG8/nnn2vevHlaunSpYmJizmrhpKQk+Xy+s8r4No/Ho+LiYpNsScrIyHA9U6o/c1m0aJEmT56sqqoq1/P79u3reqZU/13d1KlTlZubq5qaGpM1Zs2a5Xqm9X5i5VzM/eSTT5rkRkVFKTMzU3l5efrmm29cz//yyy9dz5TYx0+X3RSOCmb37t0qLS3V6NGjG7fV1tZq27Zteumll7Rr1y5FREQ0Kcvn85k9SayyKysrXc88WVVVlckaVk+Mk/Ot1rAsAMt90JLl3BYH/2/nW6zBPv792cHcxx0VzDXXXKPCwsKAbQ8++KC6du2qu+66q8nlAgBo+RwVTEJCgnr06BGwLT4+Xm3atDllOwDgwsa/5AcAmGjWjymfbMWKFW7MAQBoYTiDAQCYoGAAACYoGACACQoGAGCCggEAmKBgAAAmKBgAgAkKBgBggoIBAJigYAAAJigYAIAJCgYAYIKCAQCYoGAAACYoGACAibN+P5gLyfHjx01yq6urJUlffvmlKioqXM8fMGCA65mSGt8iu2/fvqqtrTVZI1QlJia6nunxeBqzIyNtnrpW+0p4eP33sn379lVdXZ3r+atXr3Y9U5JiYmIk1T83G56naDrOYAAAJigYAIAJCgYAYIKCAQCYoGAAACYoGACACQoGAGCCggEAmKBgAAAmKBgAgAkKBgBggoIBAJigYAAAJigYAIAJCgYAYIKCAQCYoGAAACYoGACACQoGAGDC0Rt7L1iwQAsXLgzYlpycrDfeeMPVoQAAoc9RwUhS9+7dtWzZssbbERERrg4EAGgZHBdMRESE2rdvbzELAKAFcVwwBw8eVFpammJiYtS3b19Nnz5dnTp1crywx+Nx/JimZlpkS1J8fLxJblxcXMBHt1mdZTbkWp7FhuJ+YpWdkJAQ8NFCeLjNy7INuVb5MTExprlW+VLo7eNOMsP8fr+/qXd+7733VFFRoeTkZJWUlCg3N1dHjhxRYWGh6U4PAAg9jgrm277++mulp6frgQce0NixYx09NikpST6fr7lLfyePx6Pi4mKTbElKT093PVOqP3PJz8/X+PHjVVlZ6Xr+fffd53qmVH/mMmTIEL3//vuqra01WePmm292PdN6P5GkxMRE1zMTEhK0e/du9e7dW2VlZa7nS9KGDRtMcsPDw9WnTx/t2LFDdXV1rudbzR0TE6OHHnpIjzzyiKqrq03WeOKJJ1zPtNzHG7KbwvElspNddNFF6tKliw4dOuT4sT6fz+zJbZVdUVHheubJKisrTdawOvifnG+1htU+0pBtlR8ZeVZPrdMqKyszm9vi4P/tfIs1rA7+J+dbrRGq+3hTnNUF0fLych0+fJgX/QEAp3D0bdajjz6q9PR0derUSUePHtWCBQsUHh6uG2+80Wo+AECIclQwX3zxhaZNm6Yvv/xSbdu21YABA1RQUKC2bdtazQcACFGOCsbixSgAQMvE7yIDAJigYAAAJigYAIAJCgYAYIKCAQCYoGAAACYoGACACQoGAGCCggEAmKBgAAAmKBgAgAkKBgBggoIBAJigYAAAJigYAIAJuzcOb4H2799vkpuQkCBJKioqUllZmev5AwYMcD3zZH379jXLHjt2rOuZcXFxkqSMjAxVVla6ni/ZzB0ZWf90/fOf/6wTJ064nh/KHn30UZNcj8ej7OxsPfHEE0F9b/tQxRkMAMAEBQMAMEHBAABMUDAAABMUDADABAUDADBBwQAATFAwAAATFAwAwAQFAwAwQcEAAExQMAAAExQMAMAEBQMAMEHBAABMUDAAABMUDADABAUDADBBwQAATDgumCNHjmjGjBkaOHCgUlNTNXLkSO3atctiNgBACIt0cuevvvpKt912mwYOHKjnn39eiYmJOnjwoFq3bm01HwAgRDkqmOeff14dO3ZUTk5O47ZLL73U9aEAAKHPUcG88847SktL07333qtt27apQ4cOuv322zVu3DjHC3s8HsePaWqmRbYkJSQkmOS2atUq4CP+Jy4uzvXM2NjYgI8WIiMdPbUcZVpkNwgPt3lZtiHXKt/qOW99TLFiObeTzDC/3+9v6p2vuuoqSdLEiRN1/fXXa9euXZo3b56ys7OVkZHhfFIAQIvl6Fshv9+vlJQUTZs2TZLUq1cv7du3T/n5+Y4LJikpST6fz9FjzsTj8ai4uNgkW5KSk5Ndz5Tqz1w2b96swYMHq7y83PX8TZs2uZ7ZIDExUcePHzfLv++++1zPjI2N1aJFizR58mRVVVW5ni9Jo0aNcj0zMjJSI0eOVGFhoU6cOOF6viR16dLFJDc8PFx9+vTRjh07VFdX53r+0KFDXc+U7I8pViznbshuCkcF0759e3Xr1i1gW9euXfXmm286iZEk+Xw+sy+YVXZZWZnrmScrLy83XyPUVFZWmmVXVVWZ5VsVQEO2Vb7Fwf/b+RZrWB/8LY9XloI9t6MLov3799eBAwcCthUVFSkpKcnVoQAAoc9RwWRlZWnHjh169tlndfDgQRUWFqqgoEC333671XwAgBDl6BJZamqqFi5cqMcff1y5ubnq3LmzHnroId10001W8wEAQpTjn3dMT09Xenq6xSwAgBaE30UGADBBwQAATFAwAAATFAwAwAQFAwAwQcEAAExQMAAAExQMAMAEBQMAMEHBAABMUDAAABMUDADABAUDADBBwQAATFAwAAATFAwAwITjNxy7kO3fv98k1+PxSJIOHDggn8/nev4DDzzgeqYkxcbG6sknn9Ts2bNVVVVlssb8+fNdzwwLC5MkzZ49W36/3/V8Sfroo49Mcq1dffXVJrkej0dff/21hg4darKP4/zEGQwAwAQFAwAwQcEAAExQMAAAExQMAMAEBQMAMEHBAABMUDAAABMUDADABAUDADBBwQAATFAwAAATFAwAwAQFAwAwQcEAAExQMAAAExQMAMAEBQMAMOHoLZOHDRum4uLiU7bffvvtmjVrlmtDAQBCn6OCWbNmjWpraxtv79u3TxMnTtT111/v+mAAgNDmqGDatm0bcPu5557TZZddph/96EeuDgUACH2OCuZkNTU1euWVVzRx4kSFhYU5frzH42nu0mfMtMi2ZD13bGysSW5MTEzARwvN2beammmR3SAystlPrTNmWmQ3sNoHeW6eW5ZzO8kM8/v9/uYs8tprr2nGjBl699131aFDh+ZEAABasGZ/K7R27VoNGTKk2eWSlJQkn8/X3OW/k8fjUXFxsUm2Jeu5J06c6HqmVH/m8thjj+m3v/2tqqurTda47777XM8MCwtTly5dVFRUpGZ+f3VG27dvdz0zMjJSI0eOVGFhoU6cOOF6viRlZWWZ5PLcPLcs527IbopmFUxxcbE2b96sBQsWNOfhkiSfz2f2BbPMtmQ1d1VVleuZJ6uurjZbw6oAGrKt8q0KoCHbKt/6ecNz89wK9tzN+ncw69atU7t27fTjH//Y5XEAAC2F44Kpq6vTunXrNGrUKNMXGwEAoc1xwWzevFmfffaZxowZYzEPAKCFcHwKkpaWpr1791rMAgBoQfhdZAAAExQMAMAEBQMAMEHBAABMUDAAABMUDADABAUDADBBwQAATFAwAAATFAwAwAQFAwAwQcEAAExQMAAAExQMAMAEBQMAMBG0t6T0eDxmmRbZlqznjo2NNcmNiYkJ+GghLCzMLNMiu4HFu702ZFq+k6zVPshz89yynNtJZpjf7/e7PgEA4ILHJTIAgAkKBgBggoIBAJigYAAAJigYAIAJCgYAYIKCAQCYoGAAACYoGACACQoGAGCCggEAmGgxBfPSSy9p2LBhuuqqqzR27Fjt3Lkz2COd0bZt2zRlyhSlpaXJ6/Xq7bffDvZITbJo0SKNGTNG/fr106BBg3T33Xdr//79wR7rjFauXKmRI0eqf//+6t+/v2699Va99957wR7Lseeee05er1fz5s0L9iintWDBAnm93oD/rr/++mCP1SRHjhzRjBkzNHDgQKWmpmrkyJHatWtXsMc6o2HDhp3yOfd6vcrOzg7KPEH7bcpueu2115STk6Ps7Gz16dNHy5cv16RJk/TGG2+oXbt2wR7ve1VUVMjr9WrMmDG65557gj1Ok23dulV33HGHrrrqKtXW1urxxx/XpEmT9Oqrryo+Pj7Y432vjh07asaMGbr88svl9/u1YcMGTZ06VevXr1f37t2DPV6T7Ny5U/n5+fJ6vcEepUm6d++uZcuWNd6OiIgI4jRN89VXX+m2227TwIED9fzzzysxMVEHDx5U69atgz3aGa1Zs0a1tbWNt/ft26eJEycGr9j9LcAtt9ziz87ObrxdW1vrT0tL8y9atCiIUznTo0cP/1tvvRXsMZqltLTU36NHD//WrVuDPYpjP/zhD/0FBQXBHqNJysrK/D/96U/9H374oT8zM9M/d+7cYI90Wk899ZT/pptuCvYYjv3hD3/w33bbbcEewxVz5871Dx8+3F9XVxeU9UP+EllNTY12796twYMHN24LDw/X4MGD9fHHHwdxsguHz+eTpJD4Dq9BbW2tXn31VVVUVKhfv37BHqdJ5syZo6FDhwbs6+e7gwcPKi0tTdddd52mT5+uzz77LNgjndE777yjlJQU3XvvvRo0aJBGjRqlgoKCYI/lWE1NjV555RWNGTPG9L2PTifkL5EdP35ctbW1p1wKa9euXUi8LhDq6urq9Mgjj6h///7q0aNHsMc5o71792r8+PGqrq5WfHy8cnNzdcUVVwR7rDN69dVX9a9//Utr1qwJ9ihNlpqaqpycHCUnJ6ukpES5ubm64447VFhYqISEhGCP970OHz6sVatWaeLEiZoyZYp27dqluXPnKioqShkZGcEer8nefvtt+Xy+oM4c8gWD4MrOzta+ffu0cuXKYI/SJMnJydqwYYN8Pp/efPNNzZw5U3l5eed1yXz++eeaN2+eli5davruoW4bOnRo4//37NlTffr0UXp6ul5//XWNHTs2iJOdnt/vV0pKiqZNmyZJ6tWrl/bt26f8/PyQKpi1a9dqyJAh6tChQ9BmCPlLZImJiYqIiFBpaWnA9tLSUl188cVBmurCMGfOHG3atEnLly9Xx44dgz1Ok0RHR+vyyy9XSkqKpk+frp49e+rFF18M9lintXv3bpWWlmr06NHq1auXevXqpa1bt2rFihXq1atXwIu657OLLrpIXbp00aFDh4I9ymm1b99e3bp1C9jWtWvXkLi816C4uFibN2/WLbfcEtQ5Qv4MJjo6Wr1799aWLVs0fPhwSfWXbbZs2aLMzMwgT9cy+f1+Pfzww3rrrbe0YsUKXXrppcEeqdnq6upUU1MT7DFO65prrlFhYWHAtgcffFBdu3bVXXfdFRI/mSVJ5eXlOnz4sNq3bx/sUU6rf//+OnDgQMC2oqIiJSUlBWki59atW6d27drpxz/+cVDnCPmCkaSJEydq5syZSklJUWpqqpYvX67KykqNHj062KOdVnl5ecB3c59++qn27Nmj1q1bq1OnTkGc7PSys7O1ceNGPf3002rVqpVKSkokSR6PR7GxsUGe7vv96U9/0pAhQ3TJJZeovLxcGzdu1NatW7VkyZJgj3ZaCQkJp7y+FR8frzZt2pzXr3s9+uijSk9PV6dOnXT06FEtWLBA4eHhuvHGG4M92mllZWXptttu07PPPqsbbrhBO3fuVEFBgebMmRPs0Zqkrq5O69at06hRoxQZGdxDfIsomBEjRujYsWN66qmnVFJSoiuvvFKLFy8+7y+RffLJJ5owYULj7ZycHElSRkaG5s+fH6yxzmjVqlWSpDvvvDNge05Oznld6qWlpZo5c6aOHj0qj8cjr9erJUuW6Nprrw32aC3SF198oWnTpunLL79U27ZtNWDAABUUFKht27bBHu20UlNTtXDhQj3++OPKzc1V586d9dBDD+mmm24K9mhNsnnzZn322WcaM2ZMsEdRmN/v9wd7CABAyxPyL/IDAM5PFAwAwAQFAwAwQcEAAExQMAAAExQMAMAEBQMAMEHBAABMUDAAABMUDADABAUDADDx//6/21Ts7pF0AAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 1797 images flattened to 64-values vectors\n"
     ]
    }
   ],
   "source": [
    "# Based on https://github.com/hsu-ai-course/hsu.ai/blob/master/code/12.%20kNN%20and%20ANN%20for%20MNIST.ipynb\n",
    "digits = load_digits()\n",
    "\n",
    "print(\"Dataset shape\", digits.images.shape)\n",
    "\n",
    "# show first image\n",
    "plt.title(f\"Target: {digits.target[0]}\")\n",
    "plt.imshow(digits.images[0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "print(\"Now we have {} images flattened to {}-values vectors\".format(*X.shape))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train a KNN and LR models and compare their results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       0.97      0.97      0.97        35\n",
      "           2       1.00      0.97      0.99        36\n",
      "           3       0.91      1.00      0.95        29\n",
      "           4       1.00      0.97      0.98        30\n",
      "           5       0.95      0.97      0.96        40\n",
      "           6       1.00      1.00      1.00        44\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       1.00      0.90      0.95        39\n",
      "           9       0.98      0.98      0.98        41\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.97      0.97       360\n",
      "\n",
      "LR               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       0.92      0.97      0.94        35\n",
      "           2       0.97      0.97      0.97        36\n",
      "           3       0.97      1.00      0.98        29\n",
      "           4       0.97      0.97      0.97        30\n",
      "           5       0.97      0.93      0.95        40\n",
      "           6       1.00      0.98      0.99        44\n",
      "           7       0.97      0.97      0.97        39\n",
      "           8       0.97      0.92      0.95        39\n",
      "           9       0.93      0.98      0.95        41\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Write code here\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, knn.predict(X_test)\n",
    "print('KNN', classification_report(y_true, y_pred))\n",
    "\n",
    "y_true, y_pred = y_test, LR.predict(X_test)\n",
    "print('LR', classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Which model performed better? What is the advantages of each model over the other?\n",
    "KNN performed better due to table above.\n",
    "Pros & Cons of each model:\n",
    "LR:\n",
    "    + A convenient, quick and straightforward method of classification.\n",
    "    + Parameters explain the direction and intensity of significance of the independent variables over the dependent variable.\n",
    "    + Can be used for multiclass classifications also.\n",
    "    + The function for loss is always convex.\n",
    "    - It can not be extended to problems of non-linear classification.\n",
    "    - Proper feature selection is required.\n",
    "    - A good ratio of signal to noise is required.\n",
    "    - The precision of the LR model tampers with colinearity and outliers.\n",
    "KNN:\n",
    "    + A quick and straightforward model of machine learning.\n",
    "    + A few tuneable hyperparameters.\n",
    "    - K should be chosen wisely.\n",
    "    - High runtime computing costs if the sample size is large.\n",
    "    - For equal treatment between features, proper scaling should be given.\n",
    "\n",
    "What is the output of `classification_report` function? How to interpret it?\n",
    "The reported averages include macro average (averaging the unweighted mean per label), weighted average (averaging the support-weighted mean per label), and sample average (only for multilabel classification). Micro average (averaging the total true positives, false negatives and false positives) is only shown for multi-label or multi-class with a subset of classes, because it corresponds to accuracy otherwise and would be the same for all metrics.\n",
    "\n",
    "Let's use such a variables TP, TN, FP, FN from Confusion Matrix\n",
    "and precision will be calculated as TP / (TP + FP)\n",
    "recall will be calculated as TP / (TP + FN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
